# -*- coding: utf-8 -*-
"""CNN_PreTrained.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fe0ZMgcr2CkJixsl6X5lX8QKtwoMFRmu
"""

#!/bin/bash
!curl -L -o archive.zip\
https://www.kaggle.com/api/v1/datasets/download/prasunroy/natural-images

!unzip archive.zip

import torch
import torchvision
from torchsummary import summary
import numpy as np
import matplotlib.pyplot as plt
import random
import numpy
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os
from PIL import Image
import torchvision.models as models

device = torch.device('Ã§uda' if torch.cuda.is_available() else 'cpu')

model = models.resnet18(pretrained=True)

num_classes = 8
classes = ['airplane ', 'car', 'cat', 'dog', 'flower', 'fruit', "motorbike", 'person']
model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
model.to(device)

for param in model.parameters():
    param.requires_grad = False

for param in model.fc.parameters():
    param.requires_grad = True

transformation = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),
                                                torchvision.transforms.ToTensor(),
                                                torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

data_path = '/content/natural_images'

full_dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transformation)

train_size = int(0.8 * len(full_dataset))
test_size = len(full_dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)

def test(model, test_loader, device):
  model.eval()

  with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
      images = images.to(device)
      labels = labels.to(device)
      predicted_output = model(images)
      _, predicted = torch.max(predicted_output.data, 1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
      accuracy = 100 * correct / total
    print('correct :', correct)
    print('total :', total)
    print('pred :', predicted)
  return accuracy

num_epochs = 6
learning_rate = 0.001
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

acc_list = []
epoch_losses = []
for epoch in range(num_epochs):
  epoch_loss = 0
  for i, (images, labels) in enumerate(train_loader):
    model.train()
    images = images.to(device)
#    labels = torch.eye(num_classes)[labels].to(device)
    labels = labels.to(device)

    outputs = model(images)
    outputs = torch.nn.functional.log_softmax(outputs, dim=1)
    loss = criterion(outputs, labels)

#    loss.requires_grad = True
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    epoch_loss += loss.item()

  epoch_losses.append(epoch_loss/len(train_loader))
  print(f"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}")

  acc = test(model, test_loader, device)
  acc_list.append(acc/len(train_loader))
  print(f"Average Accuracy: {acc}")

y_pred = []
y_true = []

for images, labels in test_loader:
  predicted_output = model(images)
  _, predicted = torch.max(predicted_output.data, 1)
  y_pred.extend(predicted.cpu().numpy())
  y_true.extend(labels.cpu().numpy())

cf_matrix = confusion_matrix(y_true, y_pred)
print(cf_matrix)
print(classification_report(y_true, y_pred))

epochs = range(1, len(acc_list) + 1)

plt.plot(epochs, acc_list)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy Learning Curve')
plt.grid(True)
plt.show()

epochs = range(1, len(epoch_losses) + 1)

plt.plot(epochs, epoch_losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Learning Curve')
plt.grid(True)
plt.show()

def visualize_predictions(model, test_loader, device, classes):
    """Visualizes model predictions on a random batch of images from the test_loader."""

    # Choose a random batch from the test_loader
    batch_index = random.randint(0, len(test_loader) - 1)

    for i, (images, labels) in enumerate(test_loader):
        if i == batch_index:  # Visualize images from the selected batch
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

            fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))
            for i, ax in enumerate(axes.flat):
                # Transpose the image to (height, width, channels)
                image_to_show = images[i].cpu().numpy().transpose(1, 2, 0)
                ax.imshow(image_to_show, cmap='gray')

                actual_class_name = classes[labels[i].cpu().item()]
                predicted_class_name = classes[predicted[i].cpu().item()]

                ax.set_title(f"Actual: {actual_class_name}\nPredicted: {predicted_class_name}")
                ax.axis('off')
            plt.tight_layout()
            plt.show()

            break  # Exit loop after visualizing the selected batch

# Call the function to visualize predictions
visualize_predictions(model, test_loader, device, classes)

# Assuming 'model' is your trained model
torch.save(model.state_dict(), 'pre_trained_model.pt')